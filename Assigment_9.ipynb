{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0ea22d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yellowbrick'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhierarchy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler, StandardScaler\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myellowbrick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KElbowVisualizer\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m silhouette_score \u001b[38;5;28;01mas\u001b[39;00m sil, calinski_harabasz_score \u001b[38;5;28;01mas\u001b[39;00m chs, silhouette_samples\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yellowbrick'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.metrics import silhouette_score as sil, calinski_harabasz_score as chs, silhouette_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959fdce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97151b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab60c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('EastWestAirlines.xlsx',sheet_name='data')\n",
    "\n",
    "# Column rename.\n",
    "data.rename(columns={'ID#':'ID', 'Award?':'Award'}, inplace=True)\n",
    "\n",
    "#Set ID as Index Column\n",
    "data.set_index('ID',inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a53a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3b9dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a548c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('unique_cc1',data.cc1_miles.unique())\n",
    "print('unique_cc2',data.cc2_miles.unique())\n",
    "print('unique_cc3',data.cc3_miles.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91eb7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count_col = data.isnull().sum().value_counts(ascending=False)\n",
    "\n",
    "# null percentage for columns\n",
    "\n",
    "null_percent_col = (data.isnull().sum() * 100 / len(data)).value_counts(ascending=False)\n",
    "\n",
    "print(\"Null Count for Columns:\\n\\n\", null_count_col, \"\\n\")\n",
    "print(\"Null Percentage for Columns:\\n\\n\", null_percent_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81135a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count_row = data.isnull().sum(axis=1).value_counts(ascending=False)\n",
    "\n",
    "# null percentage for rows\n",
    "\n",
    "null_percent_row = (data.isnull().sum(axis=1) * 100 / len(data)).value_counts(ascending=False)\n",
    "\n",
    "print(\"Null Count for Rows:\\n\\n\", null_count_row, \"\\n\")\n",
    "print(\"Null Percentage for Rows:\\n\\n\", null_percent_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d3a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e151647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4634e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in data.columns:\n",
    "    data=data.copy()\n",
    "    data[feature].hist(bins=25)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in data.columns:\n",
    "    print(n)\n",
    "    sns.kdeplot(data[n])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1018d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab001a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ot=data.copy() \n",
    "fig, axes=plt.subplots(10,1,figsize=(16,16),sharex=False,sharey=False)\n",
    "sns.boxplot(x='Balance',data=ot,palette='crest',ax=axes[0])\n",
    "sns.boxplot(x='Qual_miles',data=ot,palette='crest',ax=axes[1])\n",
    "sns.boxplot(x='cc1_miles',data=ot,palette='crest',ax=axes[2])\n",
    "sns.boxplot(x='cc2_miles',data=ot,palette='crest',ax=axes[3])\n",
    "sns.boxplot(x='cc3_miles',data=ot,palette='crest',ax=axes[4])\n",
    "sns.boxplot(x='Bonus_miles',data=ot,palette='crest',ax=axes[5])\n",
    "sns.boxplot(x='Bonus_trans',data=ot,palette='crest',ax=axes[6])\n",
    "sns.boxplot(x='Flight_miles_12mo',data=ot,palette='crest',ax=axes[7])\n",
    "sns.boxplot(x='Flight_trans_12',data=ot,palette='crest',ax=axes[8])\n",
    "sns.boxplot(x='Days_since_enroll',data=ot,palette='crest',ax=axes[9])\n",
    "plt.tight_layout(pad=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e7f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42caaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(data=np.sqrt(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f69713",
   "metadata": {},
   "outputs": [],
   "source": [
    "countNotermdeposit = len(data[data.Award == 0])\n",
    "counthavetermdeposit = len(data[data.Award == 1])\n",
    "print(\"Percentage of Customer doesn't have a Award: {:.2f}%\".format((countNotermdeposit / (len(data.Award))*100)))\n",
    "print(\"Percentage of Customer does have a Award: {:.2f}%\".format((counthavetermdeposit / (len(data.Award))*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513844aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Award', data=data, \n",
    "              order=data['Award'].value_counts().index)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.title('Whether the client has a Award or not ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766df90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "Balance = data[['Award','Balance']].sort_values('Balance', ascending = False)\n",
    "ax = sns.barplot(x='Award', y='Balance', data= Balance)\n",
    "ax.set(xlabel = 'Award', ylabel= 'Balance')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bbd723",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data.corr()\n",
    "corr_matrix[\"Balance\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66df206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('EastWestAirlines.xlsx',sheet_name='data')\n",
    "sns.pairplot(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6933750",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(18,12))\n",
    "sns.heatmap(data.corr(), annot=True, linewidths =.5, fmt ='.1f',ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1428541",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "sorted_data = data[['cc1_miles','Bonus_trans']].sort_values('Bonus_trans', ascending = False)\n",
    "ax = sns.barplot(x='cc1_miles', y='Bonus_trans', data= sorted_data)\n",
    "ax.set(xlabel = 'Miles earned with freq. flyer credit card', ylabel= 'Non-flight bonus transactions')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574aba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "std_df = standard_scaler.fit_transform(data)\n",
    "std_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f265aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax = MinMaxScaler()\n",
    "\n",
    "minmax_df = minmax.fit_transform(data)\n",
    "minmax_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_range = range(1,15)\n",
    "cluster_errors = []\n",
    "for num_clusters in cluster_range:\n",
    "    clusters = KMeans(num_clusters,n_init=10)\n",
    "    clusters.fit(std_df)\n",
    "    labels = clusters.labels_\n",
    "    centroids = clusters.cluster_centers_\n",
    "    cluster_errors.append(clusters.inertia_)\n",
    "clusters_df = pd.DataFrame({\"num_clusters\":cluster_range,\"cluster_errors\":cluster_errors})\n",
    "clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss=[]\n",
    "for i in range(1,9):\n",
    "    kmeans=KMeans(n_clusters=i,random_state=2)\n",
    "    kmeans.fit(std_df)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    \n",
    "# Plot K values range vs WCSS to get Elbow graph for choosing K (no. of clusters)\n",
    "plt.plot(range(1,9),wcss,color = 'black')\n",
    "plt.scatter(range(1,9),wcss,color='red')\n",
    "plt.title('Elbow Graph for Standard Scaler')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797e7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "n_clusters = [2,3,4,5,6,7,8,9,10] # number of clusters\n",
    "clusters_inertia = [] # inertia of clusters\n",
    "s_scores = [] # silhouette scores\n",
    "\n",
    "for n in n_clusters:\n",
    "    KM_est = KMeans(n_clusters=n, init='k-means++').fit(std_df)\n",
    "    clusters_inertia.append(KM_est.inertia_)    # data for the elbow method\n",
    "    silhouette_avg = silhouette_score(std_df, KM_est.labels_)\n",
    "    s_scores.append(silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27135bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "ax = sns.lineplot(n_clusters, s_scores, marker='o', ax=ax)\n",
    "ax.set_title(\"Silhouette score method\")\n",
    "ax.set_xlabel(\"number of clusters\")\n",
    "ax.set_ylabel(\"Silhouette score\")\n",
    "ax.axvline(2, ls=\"--\", c=\"red\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2047ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(random_state=10, max_iter=500, init='k-means++')\n",
    "\n",
    "# Instantiate the KElbowVisualizer with the number of clusters and the metric\n",
    "visualizer = KElbowVisualizer(model, k=(2,20), metric='silhouette', timings=False)\n",
    "# Fit the data and visualize\n",
    "print('Elbow Plot for Standard Scaler data')\n",
    "visualizer.fit(std_df)    \n",
    "visualizer.poof()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911790fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_list = [2,3,4,5,6,7,8,9]\n",
    "\n",
    "#  Silhouette score for stadardScaler applied on data.\n",
    "\n",
    "for n_clusters in clust_list:\n",
    "    clusterer1 = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    cluster_labels1 = clusterer1.fit_predict(std_df)\n",
    "    sil_score1= sil(std_df, cluster_labels1)\n",
    "    print(\"For n_clusters =\", n_clusters,\"The average silhouette_score is :\", sil_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6e6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = [2,3,4,5,6,7,8,9]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(std_df) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    cluster_labels = clusterer.fit_predict(std_df)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = sil(std_df, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(std_df, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(std_df[:,6], std_df[:, 9], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors, edgecolor='k')\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:,6], centers[:,9], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[6], c[9], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data after Standard scaler.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1863909",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kmeans = KMeans(n_clusters=6, random_state=0, init='k-means++')\n",
    "y_predict_kmeans = model_kmeans.fit_predict(std_df)\n",
    "y_predict_kmeans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b2142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a93d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9500e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac15698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7959853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('EastWestAirlines.xlsx', sheet_name='data')\n",
    "df.rename({'ID#':'ID', 'Award?':'Award'}, inplace=True, axis=1)\n",
    "df['Kmeans_label'] = model_kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1340e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Kmeans_label').agg(['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15db8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "fig,(ax1,ax2) = plt.subplots(1,2,sharey=False)\n",
    "fig.set_size_inches(15,6)\n",
    "\n",
    "\n",
    "\n",
    "sil_visualizer1 = SilhouetteVisualizer(model_kmeans,ax= ax1, colors=['#922B21','#5B2C6F','#1B4F72','#32a84a','#a83232','#323aa8'])\n",
    "sil_visualizer1.fit(std_df)\n",
    "\n",
    "\n",
    "# 2nd Plot showing the actual clusters formed\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "colors1 = cm.nipy_spectral(model_kmeans.labels_.astype(float) / 6) # 6 is number of clusters\n",
    "ax2.scatter(std_df[:, 6], std_df[:, 9], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors1, edgecolor='k')\n",
    "\n",
    "# Labeling the clusters\n",
    "centers1 = model_kmeans.cluster_centers_\n",
    "# Draw white circles at cluster centers\n",
    "ax2.scatter(centers1[:, 6], centers1[:, 9], marker='o',c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "for i, c in enumerate(centers1):\n",
    "    ax2.scatter(c[6], c[9], marker='$%d$' % i, alpha=1,s=50, edgecolor='k')\n",
    "\n",
    "\n",
    "ax2.set_title(label =\"The visualization of the clustered data.\")\n",
    "ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % 6),fontsize=14, fontweight='bold')\n",
    "\n",
    "sil_visualizer1.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "df.groupby(['Kmeans_label']).count()['ID'].plot(kind='bar')\n",
    "plt.ylabel('ID Counts')\n",
    "plt.title('Kmeans Clustering Standard Scaler Applied',fontsize='large',fontweight='bold')\n",
    "ax.set_xlabel('Clusters', fontsize='large', fontweight='bold')\n",
    "ax.set_ylabel('ID counts', fontsize='large', fontweight='bold')\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc4692",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_range = range(1,15)\n",
    "cluster_errors = []\n",
    "for num_clusters in cluster_range:\n",
    "    clusters = KMeans(num_clusters,n_init=10)\n",
    "    clusters.fit(minmax_df)\n",
    "    labels = clusters.labels_\n",
    "    centroids = clusters.cluster_centers_\n",
    "    cluster_errors.append(clusters.inertia_)\n",
    "clusters_df = pd.DataFrame({\"num_clusters\":cluster_range,\"cluster_errors\":cluster_errors})\n",
    "clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04f4aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss=[]\n",
    "for i in range (1,9):\n",
    "    kmeans=KMeans(n_clusters=i,random_state=2)\n",
    "    kmeans.fit(minmax_df)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    \n",
    "# Plot K values range vs WCSS to get Elbow graph for choosing K (no. of clusters)\n",
    "plt.plot(range(1,9),wcss,color = 'black')\n",
    "plt.scatter(range(1,9),wcss,color='red')\n",
    "plt.title('Elbow Graph for MinMaxScaler')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cebd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "n_clusters = [2,3,4,5,6,7,8,9,10] # number of clusters\n",
    "clusters_inertia = [] # inertia of clusters\n",
    "s_scores = [] # silhouette scores\n",
    "\n",
    "for n in n_clusters:\n",
    "    KM_est = KMeans(n_clusters=n, init='k-means++').fit(minmax_df)\n",
    "    clusters_inertia.append(KM_est.inertia_)    # data for the elbow method\n",
    "    silhouette_avg = silhouette_score(minmax_df, KM_est.labels_)\n",
    "    s_scores.append(silhouette_avg) # data for the silhouette score method\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "ax = sns.lineplot(n_clusters, s_scores, marker='o', ax=ax)\n",
    "ax.set_title(\"Silhouette score method\")\n",
    "ax.set_xlabel(\"number of clusters\")\n",
    "ax.set_ylabel(\"Silhouette score\")\n",
    "ax.axvline(2, ls=\"--\", c=\"red\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817efc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(random_state=10, max_iter=500, init='k-means++')\n",
    "\n",
    "# Instantiate the KElbowVisualizer with the number of clusters and the metric\n",
    "visualizer = KElbowVisualizer(model, k=(2,20), metric='silhouette', timings=False)\n",
    "# Fit the data and visualize\n",
    "print('Elbow Plot for MinMaxScaler data')\n",
    "visualizer.fit(minmax_df)    \n",
    "visualizer.poof()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a698463",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_list = [2,3,4,5,6,7,8,9]\n",
    "\n",
    "#  Silhouette score for MinMaxScaler Applied on data .\n",
    "\n",
    "for n_clusters in clust_list:\n",
    "    clusterer1 = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    cluster_labels1 = clusterer1.fit_predict(minmax_df)\n",
    "    sil_score1= sil(minmax_df, cluster_labels1)\n",
    "    print(\"For n_clusters =\", n_clusters,\"The average silhouette_score is :\", sil_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = [2,3,4,5,6,7,8,9]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(minmax_df) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(minmax_df)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = sil(minmax_df, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(minmax_df, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(minmax_df[:,6], minmax_df[:,9], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors, edgecolor='k')\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:,6], centers[:,9], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[6], c[9], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data after Standard scaler.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22eda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_kmeans = KMeans(n_clusters=2, random_state=0, init='k-means++')\n",
    "y_predict_kmeans = model_kmeans.fit_predict(minmax_df)\n",
    "y_predict_kmeans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724b3c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b17681",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8babfc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec11e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign clusters to the data set\n",
    "df = pd.read_excel('EastWestAirlines.xlsx', sheet_name='data')\n",
    "df.rename({'ID#':'ID', 'Award?':'Award'}, inplace=True, axis=1)\n",
    "df['Kmeans_label'] = model_kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b67de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "fig,(ax1,ax2) = plt.subplots(1,2,sharey=False)\n",
    "fig.set_size_inches(15,6)\n",
    "\n",
    "\n",
    "\n",
    "sil_visualizer1 = SilhouetteVisualizer(model_kmeans,ax= ax1, colors=['#922B21','#5B2C6F','#1B4F72','#32a84a'])\n",
    "sil_visualizer1.fit(minmax_df)\n",
    "\n",
    "\n",
    "# 2nd Plot showing the actual clusters formed\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "colors1 = cm.nipy_spectral(model_kmeans.labels_.astype(float) / 2) # 2 is number of clusters\n",
    "ax2.scatter(minmax_df[:, 6], minmax_df[:, 9], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors1, edgecolor='k')\n",
    "\n",
    "# Labeling the clusters\n",
    "centers1 = model_kmeans.cluster_centers_\n",
    "# Draw white circles at cluster centers\n",
    "ax2.scatter(centers1[:, 6], centers1[:, 9], marker='o',c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "for i, c in enumerate(centers1):\n",
    "    ax2.scatter(c[6], c[9], marker='$%d$' % i, alpha=1,s=50, edgecolor='k')\n",
    "\n",
    "\n",
    "ax2.set_title(label =\"The visualization of the clustered data.\")\n",
    "ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % 4),fontsize=14, fontweight='bold')\n",
    "\n",
    "sil_visualizer1.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "df.groupby(['Kmeans_label']).count()['ID'].plot(kind='bar')\n",
    "plt.ylabel('ID Counts')\n",
    "plt.title('Kmeans Clustering Standard Scaler Applied',fontsize='large',fontweight='bold')\n",
    "ax.set_xlabel('Clusters', fontsize='large', fontweight='bold')\n",
    "ax.set_ylabel('ID counts', fontsize='large', fontweight='bold')\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Kmeans_label').agg(['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d1c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for methods in ['single','complete','average','weighted','centroid','median','ward']: \n",
    "    plt.figure(figsize =(20, 6)) \n",
    "    \n",
    "    dict = {'fontsize':24,'fontweight' :16, 'color' : 'blue'}\n",
    "    \n",
    "    plt.title('Visualising the data, Method- {}'.format(methods),fontdict = dict) \n",
    "    Dendrogram1 = sch.dendrogram(sch.linkage(minmax_df, method = methods,optimal_ordering=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceafa799",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = [2,3,4,5,6,7,8]  # always start number from 2.\n",
    "\n",
    "for n_clusters in n_clusters:\n",
    "    for linkages in [\"ward\", \"complete\", \"average\", \"single\"]:\n",
    "        hie_cluster1 = AgglomerativeClustering(n_clusters=n_clusters,linkage=linkages) # bydefault it takes linkage 'ward'\n",
    "        hie_labels1 = hie_cluster1.fit_predict(minmax_df)\n",
    "        silhouette_score1 = sil(minmax_df, hie_labels1)\n",
    "        print(\"For n_clusters =\", n_clusters,\"The average silhouette_score with linkage-\",linkages, ':',silhouette_score1)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74671f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = [2,3,4,5,6,7,8,9,10]  # always start number from 2.\n",
    "\n",
    "for n_clusters in n_clusters:\n",
    "    for linkages in [\"ward\", \"complete\", \"average\", \"single\"]:\n",
    "        hie_cluster1 = AgglomerativeClustering(n_clusters=n_clusters,linkage=linkages) # bydefault it takes linkage 'ward'\n",
    "        hie_labels1 = hie_cluster1.fit_predict(std_df)\n",
    "        silhouette_score1 = sil(std_df, hie_labels1)\n",
    "        print(\"For n_clusters =\", n_clusters,\"The average silhouette_score with linkage-\",linkages, ':',silhouette_score1)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_std = PCA(random_state=10, n_components=0.95)\n",
    "pca_std_df= pca_std.fit_transform(std_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3be0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca_std.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda04b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca_std.explained_variance_ratio_*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf058fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_variance = np.cumsum(pca_std.explained_variance_ratio_*100)\n",
    "cum_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = [2,3,4,5,6,7,8,9,10,11,12,13,14,15]  # always start number from 2.\n",
    "\n",
    "for n_clusters in n_clusters:\n",
    "    for linkages in [\"ward\", \"complete\", \"average\", \"single\"]:\n",
    "        hie_cluster1 = AgglomerativeClustering(n_clusters=n_clusters,linkage=linkages) # bydefault it takes linkage 'ward'\n",
    "        hie_labels1 = hie_cluster1.fit_predict(pca_std_df)\n",
    "        silhouette_score1 = sil(pca_std_df, hie_labels1)\n",
    "        print(\"For n_clusters =\", n_clusters,\"The average silhouette_score with linkage-\",linkages, ':',silhouette_score1)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b571ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_hie = agg_clustering.fit_predict(pca_std_df)\n",
    "print(y_pred_hie.shape)\n",
    "y_pred_hie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_clustering.n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sil(pca_std_df, agg_clustering.labels_)*100).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a8f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hierarchical_labels'] = agg_clustering.labels_\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967df32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Hierarchical_labels').agg(['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8edb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "df.groupby(['Hierarchical_labels']).count()['ID'].plot(kind='bar')\n",
    "plt.ylabel('ID Counts')\n",
    "plt.title('Hierarchical Clustering PCA MinMax Scaled Data',fontsize='large',fontweight='bold')\n",
    "ax.set_xlabel('Clusters', fontsize='large', fontweight='bold')\n",
    "ax.set_ylabel('ID counts', fontsize='large', fontweight='bold')\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1399b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_minmax =  PCA(random_state=10, n_components=0.95)\n",
    "pca_minmax_df = pca_minmax.fit_transform(minmax_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597d3250",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(pca_minmax.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720cf4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca_minmax.explained_variance_ratio_*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1744d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = [2,3,4,5,6,7,8]  # always start number from 2.\n",
    "\n",
    "for n_clusters in n_clusters:\n",
    "    for linkages in [\"ward\", \"complete\", \"average\", \"single\"]:\n",
    "        hie_cluster2 = AgglomerativeClustering(n_clusters=n_clusters,linkage=linkages) # bydefault it takes linkage 'ward'\n",
    "        hie_labels2 = hie_cluster2.fit_predict(pca_minmax_df)\n",
    "        silhouette_score2 = sil(pca_minmax_df, hie_labels2)\n",
    "        print(\"For n_clusters =\", n_clusters,\"The average silhouette_score with linkage-\",linkages, ':',silhouette_score2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_clustering = AgglomerativeClustering(n_clusters=2, linkage='ward')\n",
    "y_pred_hie = agg_clustering.fit_predict(pca_minmax_df)\n",
    "print(y_pred_hie.shape)\n",
    "y_pred_hie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d71ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_clustering.n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efab2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sil(pca_minmax_df, agg_clustering.labels_)*100).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d9727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hierarchical_labels'] = agg_clustering.labels_\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d00fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Hierarchical_labels').agg(['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "df.groupby(['Hierarchical_labels']).count()['ID'].plot(kind='bar')\n",
    "plt.ylabel('ID Counts')\n",
    "plt.title('Hierarchical Clustering PCA MinMax Scaled Data',fontsize='large',fontweight='bold')\n",
    "ax.set_xlabel('Clusters', fontsize='large', fontweight='bold')\n",
    "ax.set_ylabel('ID counts', fontsize='large', fontweight='bold')\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166dead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eps_values = np.arange(0.25,3,0.25) # eps values to be investigated\n",
    "min_samples = np.arange(3,23) # min_samples values to be investigated\n",
    "DBSCAN_params = list(product(eps_values, min_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_clusters = []\n",
    "sil_score = []\n",
    "\n",
    "for p in DBSCAN_params:\n",
    "    DBS_clustering = DBSCAN(eps=p[0], min_samples=p[1]).fit(std_df)\n",
    "    no_of_clusters.append(len(np.unique(DBS_clustering.labels_)))\n",
    "    sil_score.append(silhouette_score(std_df, DBS_clustering.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d8b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame.from_records(DBSCAN_params, columns =['Eps', 'Min_samples'])   \n",
    "tmp['No_of_clusters'] = no_of_clusters\n",
    "\n",
    "pivot_1 = pd.pivot_table(tmp, values='No_of_clusters', index='Min_samples', columns='Eps')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "sns.heatmap(pivot_1, annot=True,annot_kws={\"size\": 16}, cmap=\"YlGnBu\", ax=ax)\n",
    "ax.set_title('Number of clusters')\n",
    "print('A heatplot below shows how many clusters were genreated by the algorithm for the respective parameters combinations.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51abe6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame.from_records(DBSCAN_params, columns =['Eps', 'Min_samples'])   \n",
    "tmp['Sil_score'] = sil_score\n",
    "\n",
    "pivot_1 = pd.pivot_table(tmp, values='Sil_score', index='Min_samples', columns='Eps')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "sns.heatmap(pivot_1, annot=True, annot_kws={\"size\": 10}, cmap=\"YlGnBu\", ax=ax)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = [0.25,0.5,0.75,1,1.25,1.5,1.75,2,2.25,2.5,2.75]\n",
    "min_samples = [3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "\n",
    "\n",
    "sil_avg = []\n",
    "max_value = [0,0,0,0]\n",
    "\n",
    "for i in range(len(epsilon)):\n",
    "    for j in range(len(min_samples)):\n",
    "\n",
    "        db = DBSCAN(min_samples = min_samples[j], eps =epsilon[i]).fit(std_df)\n",
    "        #cluster_labels=dbscan.fit_predict(data) \n",
    "        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "        core_samples_mask[db.core_sample_indices_] = True\n",
    "        labels = db.labels_\n",
    "\n",
    "        # Number of clusters in labels, ignoring noise if present.\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise_ = list(labels).count(-1)\n",
    "\n",
    "\n",
    "        silhouette_avg = sil(std_df, labels)\n",
    "        if silhouette_avg > max_value[3]:\n",
    "            max_value=(epsilon[i], min_samples[j], n_clusters_, silhouette_avg)\n",
    "        sil_avg.append(silhouette_avg)\n",
    "\n",
    "print(\"epsilon=\", max_value[0], \n",
    "      \"\\nmin_sample=\", max_value[1],\n",
    "      \"\\nnumber of clusters=\", max_value[2],\n",
    "      \"\\naverage silhouette score= %.4f\" % max_value[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=2.5, min_samples=21)\n",
    "dbscan.fit(std_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b7a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DBSCAN_labels'] = dbscan.labels_\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('DBSCAN_labels').agg(['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63c39e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "df.groupby(['DBSCAN_labels']).count()['ID'].plot(kind='bar')\n",
    "plt.ylabel('ID Counts')\n",
    "plt.title('DBSCAN Clustering Standard Scaled Data',fontsize='large',fontweight='bold')\n",
    "ax.set_xlabel('Clusters', fontsize='large', fontweight='bold')\n",
    "ax.set_ylabel('ID counts', fontsize='large', fontweight='bold')\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6962b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "eps_values = np.arange(0.25,1.25,0.25) # eps values to be investigated\n",
    "min_samples = np.arange(3,23) # min_samples values to be investigated\n",
    "DBSCAN_params = list(product(eps_values, min_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567fcc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_clusters = []\n",
    "sil_score = []\n",
    "\n",
    "for p in DBSCAN_params:\n",
    "    DBS_clustering = DBSCAN(eps=p[0], min_samples=p[1]).fit(minmax_df)\n",
    "    no_of_clusters.append(len(np.unique(DBS_clustering.labels_)))\n",
    "    sil_score.append(silhouette_score(minmax_df, DBS_clustering.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e3c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame.from_records(DBSCAN_params, columns =['Eps', 'Min_samples'])   \n",
    "tmp['No_of_clusters'] = no_of_clusters\n",
    "\n",
    "pivot_1 = pd.pivot_table(tmp, values='No_of_clusters', index='Min_samples', columns='Eps')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "sns.heatmap(pivot_1, annot=True,annot_kws={\"size\": 16}, cmap=\"YlGnBu\", ax=ax)\n",
    "ax.set_title('Number of clusters')\n",
    "print('A heatplot below shows how many clusters were genreated by the algorithm for the respective parameters combinations.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38303dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame.from_records(DBSCAN_params, columns =['Eps', 'Min_samples'])   \n",
    "tmp['Sil_score'] = sil_score\n",
    "\n",
    "pivot_1 = pd.pivot_table(tmp, values='Sil_score', index='Min_samples', columns='Eps')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "sns.heatmap(pivot_1, annot=True, annot_kws={\"size\": 10}, cmap=\"YlGnBu\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a4f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = [0.25,0.5,0.75,1]\n",
    "min_samples = [11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "\n",
    "\n",
    "sil_avg = []\n",
    "max_value = [0,0,0,0]\n",
    "\n",
    "for i in range(len(epsilon)):\n",
    "    for j in range(len(min_samples)):\n",
    "\n",
    "        db = DBSCAN(min_samples = min_samples[j], eps =epsilon[i]).fit(minmax_df)\n",
    "        #cluster_labels=dbscan.fit_predict(data) \n",
    "        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "        core_samples_mask[db.core_sample_indices_] = True\n",
    "        labels = db.labels_\n",
    "\n",
    "        # Number of clusters in labels, ignoring noise if present.\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise_ = list(labels).count(-1)\n",
    "\n",
    "\n",
    "        silhouette_avg = sil(minmax_df, labels)\n",
    "        if silhouette_avg > max_value[3]:\n",
    "            max_value=(epsilon[i], min_samples[j], n_clusters_, silhouette_avg)\n",
    "        sil_avg.append(silhouette_avg)\n",
    "\n",
    "print(\"epsilon=\", max_value[0], \n",
    "      \"\\nmin_sample=\", max_value[1],\n",
    "      \"\\nnumber of clusters=\", max_value[2],\n",
    "      \"\\naverage silhouette score= %.4f\" % max_value[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba994dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = [0.25,0.5,0.75,1]\n",
    "min_samples = [3,4,5,6,7,8,9,10,11]\n",
    "\n",
    "\n",
    "sil_avg = []\n",
    "max_value = [0,0,0,0]\n",
    "\n",
    "for i in range(len(epsilon)):\n",
    "    for j in range(len(min_samples)):\n",
    "\n",
    "        db = DBSCAN(min_samples = min_samples[j], eps =epsilon[i]).fit(minmax_df)\n",
    "        #cluster_labels=dbscan.fit_predict(data) \n",
    "        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "        core_samples_mask[db.core_sample_indices_] = True\n",
    "        labels = db.labels_\n",
    "\n",
    "        # Number of clusters in labels, ignoring noise if present.\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise_ = list(labels).count(-1)\n",
    "\n",
    "\n",
    "        silhouette_avg = sil(minmax_df, labels)\n",
    "        if silhouette_avg > max_value[3]:\n",
    "            max_value=(epsilon[i], min_samples[j], n_clusters_, silhouette_avg)\n",
    "        sil_avg.append(silhouette_avg)\n",
    "\n",
    "print(\"epsilon=\", max_value[0], \n",
    "      \"\\nmin_sample=\", max_value[1],\n",
    "      \"\\nnumber of clusters=\", max_value[2],\n",
    "      \"\\naverage silhouette score= %.4f\" % max_value[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b0164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=1, min_samples=22) # min_samples = number of clumns * 3\n",
    "dbscan.fit(minmax_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27573b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7348ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DBSCAN_labels'] = dbscan.labels_\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d869e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('DBSCAN_labels').agg(['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec1eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "df.groupby(['DBSCAN_labels']).count()['ID'].plot(kind='bar')\n",
    "plt.ylabel('ID Counts')\n",
    "plt.title('DBSCAN Clustering MinMax Scaled Data',fontsize='large',fontweight='bold')\n",
    "ax.set_xlabel('Clusters', fontsize='large', fontweight='bold')\n",
    "ax.set_ylabel('ID counts', fontsize='large', fontweight='bold')\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = pd.DataFrame(df.loc[df.DBSCAN_labels==0].mean(),columns= ['Cluster1_avg'])\n",
    "cluster2 = pd.DataFrame(df.loc[df.DBSCAN_labels==1].mean(),columns= ['Cluster2_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b67e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df = pd.concat([cluster1,cluster2],axis=1)\n",
    "avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f8daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , row in avg_df.iterrows():\n",
    "    fig = plt.subplots(figsize=(8,6))\n",
    "    j = avg_df.xs(i ,axis = 0)\n",
    "    plt.title(i, fontsize=16, fontweight=20)\n",
    "    j.plot(kind='bar',fontsize=14)\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709de37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d040365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57afa04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
